{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"/Users/roysung/py_projects/hm_personal_dataset/transactions_train.csv\",\n",
    "    dtype={'customer_id': 'category', 'article_id': 'category', 'sales_channel_id': 'category'},\n",
    "    parse_dates=['t_dat']). \\\n",
    "    assign(week=lambda x: (x['t_dat'].max() - x['t_dat']).dt.days // 7)\n",
    "\n",
    "user_dt = data. \\\n",
    "    groupby(['customer_id', 't_dat'], observed=True). \\\n",
    "    agg(item_num=('article_id', 'size')). \\\n",
    "    reset_index(). \\\n",
    "    sort_values(['customer_id', 't_dat']). \\\n",
    "    assign(duration=lambda x: x.groupby('customer_id')['t_dat'].diff().dt.days)\n",
    "\n",
    "## 購買日期 2018-09-20 ~ 2020-09-22\n",
    "## 平均回購天數 48 天，中位數 22 天\n",
    "## 每次平均購買件數 3.5 件商品，中位數 2 件\n",
    "user_dt.describe()\n",
    "\n",
    "## 用戶的平均回購天數 90 天，中位數 60 天\n",
    "## 用戶平均購買 6.66 次，中位數 3 次\n",
    "## 用戶每次的平均購買數量 3.5 件商品，中位數 2.83 件\n",
    "customer_info = user_dt. \\\n",
    "    groupby('customer_id', observed=True). \\\n",
    "    agg(\n",
    "        buy_num=('t_dat', 'count'),\n",
    "        avg_interval=('duration', 'mean'),\n",
    "        avg_item_num=('item_num', 'mean'))\n",
    "customer_info.describe()\n",
    "\n",
    "# CF 模型去除雜訊\n",
    "## 只買過 1 次且商品只有 1 件的人: 131,514\n",
    "customer_info[(customer_info['buy_num']==1) & (customer_info['avg_item_num']==1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roysung/miniforge3/envs/torchenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn.models import LightGCN\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.utils.sparse import to_torch_coo_tensor\n",
    "\n",
    "\n",
    "TRANSACTIONS_DIR = \"/Users/roysung/py_projects/hm_personal_dataset/transactions_train.csv\"\n",
    "CUSTOMERS_DIR = \"/Users/roysung/py_projects/hm_personal_dataset/customers.csv\"\n",
    "ARTICLES_DIR = \"/Users/roysung/py_projects/hm_personal_dataset/articles.csv\"\n",
    "\n",
    "\n",
    "class SequenceEncoder:\n",
    "    \"\"\"\n",
    "    :param model_name: 预训练编码模型的名称\n",
    "    :param device: 选择将数据载入至cuda或者cpu\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n",
    "        self.device = device\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, df):\n",
    "        x = self.model.encode(df.values, show_progress_bar=True,\n",
    "                              convert_to_tensor=True, device=self.device)\n",
    "        return x.cpu()\n",
    "\n",
    "\n",
    "class OneHotEncoder(object):\n",
    "    def __init__(self, sep='|'):\n",
    "        self.sep = sep\n",
    "\n",
    "    def __call__(self, df):\n",
    "        # 对题材集合进行编码\n",
    "        df = df.astype('str').astype('category')\n",
    "        mapping = {cls: i for i, cls in enumerate(df.unique())}\n",
    " \n",
    "        # 采用类似one-hot编码，编码长度为num_genres，输出维度为[num_samples, num_genres]\n",
    "        x = torch.zeros(len(df), len(mapping))\n",
    "        for i, cls in enumerate(df.values):\n",
    "            # 同一个电影存在多个题材，在归属于该题材的编码位上置1，其他位置0\n",
    "            x[i, mapping[cls]] = 1\n",
    "        return x\n",
    "\n",
    "\n",
    "class AgeEncoder(OneHotEncoder):\n",
    "    def __init__(self, bin):\n",
    "        self.bin = bin\n",
    "        self.labels = range(len(bin) - 1)\n",
    "\n",
    "    def __call__(self, df):\n",
    "        df = pd.cut(df, bins=self.bin, labels=self.labels)\n",
    "        return super().__call__(df)\n",
    "\n",
    "\n",
    "def load_node_csv(path, index_col, encoders=None, **kwargs):\n",
    "    df = pd.read_csv(path, index_col=index_col, dtype={index_col: 'category'}, **kwargs)\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "\n",
    "    x = None\n",
    "    if encoders is not None:\n",
    "        xs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        x = torch.cat(xs, dim=-1)\n",
    "\n",
    "    return x, mapping\n",
    "\n",
    "\n",
    "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping,\n",
    "                  encoders=None, p_test=0.4, **kwargs):\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        dtype={src_index_col: 'category', dst_index_col: 'category'},\n",
    "        parse_dates=['t_dat']). \\\n",
    "        assign(week=lambda x: (x['t_dat'].max() - x['t_dat']).dt.days // 7)\n",
    "\n",
    "    # filter\n",
    "    low_freq_user = df. \\\n",
    "        groupby(['customer_id', 't_dat'], observed=True). \\\n",
    "        agg(item_num=('article_id', 'size')). \\\n",
    "        reset_index(). \\\n",
    "        groupby('customer_id', observed=True). \\\n",
    "        agg(\n",
    "            buy_num=('t_dat', 'count'),\n",
    "            avg_item_num=('item_num', 'mean')). \\\n",
    "        query('buy_num == 1 and avg_item_num == 1').index\n",
    "    \n",
    "    df = df[~df['customer_id'].isin(low_freq_user)]. \\\n",
    "        sort_values([src_index_col, dst_index_col])\n",
    "\n",
    "    # create edge index\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    edge_index = torch.tensor([src, dst])\n",
    "\n",
    "    # create the mask for test data\n",
    "    test_mask = torch.tensor((df['week'] == 0).to_numpy())\n",
    "\n",
    "    # create edge attributes\n",
    "    edge_attr = None\n",
    "    if encoders is not None:\n",
    "        edge_attrs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        edge_attr = torch.cat(edge_attrs, dim=-1)\n",
    "\n",
    "    return edge_index, edge_attr, test_mask\n",
    "\n",
    "\n",
    "# c_x, c_mapping = load_node_csv(\n",
    "#     CUSTOMERS_DIR,\n",
    "#     index_col=\"customer_id\",\n",
    "#     encoders={\n",
    "#         \"FN\": OneHotEncoder(),\n",
    "#         \"Active\": OneHotEncoder(),\n",
    "#         \"club_member_status\": OneHotEncoder(),\n",
    "#         \"fashion_news_frequency\": OneHotEncoder(),\n",
    "#         \"age\": AgeEncoder([0, 30, 40, 50, 60, 100]) })\n",
    "_, c_mapping = load_node_csv(CUSTOMERS_DIR, \"customer_id\")\n",
    "_, a_mapping = load_node_csv(ARTICLES_DIR, \"article_id\")\n",
    "edge_index, _, test_mask = load_edge_csv(\n",
    "    TRANSACTIONS_DIR,\n",
    "    src_index_col='customer_id',\n",
    "    src_mapping=c_mapping,\n",
    "    dst_index_col='article_id',\n",
    "    dst_mapping=a_mapping)\n",
    "\n",
    "data = HeteroData({\n",
    "    \"customer\": {\"num_nodes\": len(c_mapping)}, #{\"x\": c_x},\n",
    "    \"article\": {\"num_nodes\": len(a_mapping)},\n",
    "    (\"customer\", \"rates\", \"article\"): {\"edge_index\": edge_index}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"#torch.device(\"mps\")\n",
    "\n",
    "num_users, num_items = len(c_mapping), len(a_mapping)\n",
    "data = data.to_homogeneous().to(device)\n",
    "\n",
    "# Use all message passing edges as training labels:\n",
    "batch_size = 8192\n",
    "train_edge_index = data.edge_index[:, ~test_mask]\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    range(train_edge_index.size(1)),\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_edge_index = data.edge_index[:, test_mask]\n",
    "\n",
    "# Build model\n",
    "model = LightGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    embedding_dim=64,\n",
    "    num_layers=2,\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dcg(target: torch.Tensor) -> torch.Tensor:\n",
    "    denom = torch.log2(torch.arange(target.shape[-1], device=target.device) + 2.0)\n",
    "    return (target / denom).sum(dim=-1)\n",
    "\n",
    "\n",
    "def train_step(index: torch.Tensor, num_users: int, num_items: int, optimizer):\n",
    "    # Sample positive and negative labels.\n",
    "    pos_edge_index = train_edge_index[:, index]\n",
    "    neg_edge_index = torch.stack([\n",
    "        pos_edge_index[0],\n",
    "        torch.randint(\n",
    "            low=num_users,\n",
    "            high=num_users + num_items,\n",
    "            size=(index.numel(), ),\n",
    "            device=device)\n",
    "    ], dim=0)\n",
    "    edge_label_index = torch.cat(\n",
    "        [pos_edge_index, neg_edge_index], dim=1)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    pos_rank, neg_rank = model(data.edge_index, edge_label_index).chunk(2)\n",
    "\n",
    "    loss = model.recommendation_loss(\n",
    "        pos_rank, neg_rank, node_id=edge_label_index.unique())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_step(test_mask: torch.Tensor, k: int, num_users: int):\n",
    "    emb = model.get_embedding(data.edge_index)\n",
    "    user_emb, item_emb = emb[:num_users], emb[num_users:]\n",
    "\n",
    "    ndcg = precision = recall = total_examples = 0\n",
    "    for start in range(0, num_users, batch_size):\n",
    "        end = start + batch_size\n",
    "        logits = user_emb[start:end] @ item_emb.t()\n",
    "\n",
    "        # Exclude training edges:\n",
    "        mask = ((train_edge_index[0] >= start) &\n",
    "                (train_edge_index[0] < end))\n",
    "        logits[train_edge_index[0, mask] - start,\n",
    "               train_edge_index[1, mask] - num_users] = float('-inf')\n",
    "\n",
    "        # Computing ndcg, precision and recall:\n",
    "        ground_truth = torch.zeros_like(logits, dtype=torch.bool)\n",
    "        mask = ((data.edge_index[0] >= start) &\n",
    "                (data.edge_index[0] < end) &\n",
    "                test_mask)\n",
    "        ground_truth[data.edge_index[0, mask] - start,\n",
    "                     data.edge_index[1, mask] - num_users] = True\n",
    "        node_count = degree(\n",
    "            data.edge_index[0, mask] - start,\n",
    "            num_nodes=logits.size(0))\n",
    "\n",
    "        topk_index = logits.topk(k, dim=-1).indices\n",
    "        sorted_truth = ground_truth.gather(1, topk_index)\n",
    "        ideal_truth = torch.sort(ground_truth, descending=True).values[:, :20]\n",
    "\n",
    "        sorted_dcg = _dcg(sorted_truth)\n",
    "        ideal_dcg = _dcg(ideal_truth)\n",
    "\n",
    "        ndcg += float((sorted_dcg[ideal_dcg != 0] / ideal_dcg[ideal_dcg != 0]).sum())\n",
    "        precision += float((sorted_truth.sum(dim=-1) / k).sum())\n",
    "        recall += float((sorted_truth.sum(dim=-1) / node_count.clamp(1e-6)).sum())\n",
    "        total_examples += int((node_count > 0).sum())\n",
    "    return ndcg / total_examples, precision / total_examples, recall / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 50/3836 [13:16<79:52:39, 75.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00050, Loss: 0.6931, NDCG@20: 0.0007, Precision@20: 0.0002, Recall@20: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 100/3836 [26:43<79:45:02, 76.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00100, Loss: 0.6931, NDCG@20: 0.0007, Precision@20: 0.0002, Recall@20: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 150/3836 [40:08<78:24:22, 76.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00150, Loss: 0.6930, NDCG@20: 0.0011, Precision@20: 0.0003, Recall@20: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 199/3836 [51:38<15:43:54, 15.57s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loss \u001b[39m=\u001b[39m train_step(index, num_users, num_items, optimizer)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m50\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     ndcg, precision, recall \u001b[39m=\u001b[39m test_step(test_mask, \u001b[39m20\u001b[39;49m, num_users)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mStep: \u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m:\u001b[39;00m\u001b[39m05d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, NDCG@20: \u001b[39m\u001b[39m{\u001b[39;00mndcg\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Precision@20: \u001b[39m\u001b[39m{\u001b[39;00mprecision\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Recall@20: \u001b[39m\u001b[39m{\u001b[39;00mrecall\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/torchenv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Exclude training edges:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m mask \u001b[39m=\u001b[39m ((train_edge_index[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m start) \u001b[39m&\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         (train_edge_index[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m end))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m logits[train_edge_index[\u001b[39m0\u001b[39m, mask] \u001b[39m-\u001b[39m start,\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m        train_edge_index[\u001b[39m1\u001b[39m, mask] \u001b[39m-\u001b[39m num_users] \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m-inf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# Computing ndcg, precision and recall:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roysung/py_projects/hm_personal/graph_data_discover.ipynb#X34sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m ground_truth \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(logits, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbool)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2):\n",
    "    step = 1\n",
    "    for index in tqdm(train_loader):\n",
    "        loss = train_step(index, num_users, num_items, optimizer)\n",
    "        # if step % 50 == 0:\n",
    "        #     ndcg, precision, recall = test_step(test_mask, 20, num_users)\n",
    "        #     print(f'Step: {step:05d}, Loss: {loss:.4f}, NDCG@20: {ndcg:.4f}, Precision@20: {precision:.4f}, Recall@20: {recall:.4f}')\n",
    "        # step += 1\n",
    "    ndcg, precision, recall = test_step(test_mask, 20, num_users)\n",
    "    print(f'Step: {step:05d}, NDCG@20: {ndcg:.4f}, Precision@20: {precision:.4f}, Recall@20: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50/2641 [13:23<55:38:51, 77.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00050, Loss: 0.6931, NDCG@20: 0.0024, Precision@20: 0.0019, Recall@20: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 100/2641 [26:43<54:35:15, 77.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00100, Loss: 0.6931, NDCG@20: 0.0023, Precision@20: 0.0017, Recall@20: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 150/2641 [40:01<53:30:20, 77.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00150, Loss: 0.6931, NDCG@20: 0.0031, Precision@20: 0.0023, Recall@20: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 200/2641 [53:20<52:26:52, 77.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00200, Loss: 0.6925, NDCG@20: 0.0053, Precision@20: 0.0040, Recall@20: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 250/2641 [1:06:42<51:35:51, 77.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00250, Loss: 0.6906, NDCG@20: 0.0079, Precision@20: 0.0061, Recall@20: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 300/2641 [1:19:44<46:42:05, 71.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00300, Loss: 0.6842, NDCG@20: 0.0097, Precision@20: 0.0075, Recall@20: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 350/2641 [1:32:49<49:25:26, 77.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00350, Loss: 0.6702, NDCG@20: 0.0109, Precision@20: 0.0084, Recall@20: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 400/2641 [1:46:06<47:27:39, 76.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00400, Loss: 0.6465, NDCG@20: 0.0116, Precision@20: 0.0089, Recall@20: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 450/2641 [1:59:13<46:28:17, 76.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00450, Loss: 0.6126, NDCG@20: 0.0122, Precision@20: 0.0093, Recall@20: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 500/2641 [2:12:43<47:01:37, 79.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00500, Loss: 0.5726, NDCG@20: 0.0126, Precision@20: 0.0096, Recall@20: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 550/2641 [2:26:10<45:07:46, 77.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00550, Loss: 0.5379, NDCG@20: 0.0129, Precision@20: 0.0099, Recall@20: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 600/2641 [2:39:29<43:35:13, 76.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00600, Loss: 0.5056, NDCG@20: 0.0131, Precision@20: 0.0100, Recall@20: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 650/2641 [2:52:44<42:24:47, 76.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00650, Loss: 0.4758, NDCG@20: 0.0133, Precision@20: 0.0102, Recall@20: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 700/2641 [3:05:58<41:18:06, 76.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00700, Loss: 0.4500, NDCG@20: 0.0134, Precision@20: 0.0102, Recall@20: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 750/2641 [3:19:12<40:15:04, 76.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00750, Loss: 0.4265, NDCG@20: 0.0134, Precision@20: 0.0101, Recall@20: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 800/2641 [3:32:27<39:09:44, 76.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00800, Loss: 0.4130, NDCG@20: 0.0135, Precision@20: 0.0102, Recall@20: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 850/2641 [3:45:52<38:45:23, 77.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00850, Loss: 0.3959, NDCG@20: 0.0136, Precision@20: 0.0104, Recall@20: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 900/2641 [3:59:05<36:42:24, 75.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00900, Loss: 0.3824, NDCG@20: 0.0137, Precision@20: 0.0105, Recall@20: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 950/2641 [4:12:26<36:31:11, 77.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00950, Loss: 0.3649, NDCG@20: 0.0138, Precision@20: 0.0105, Recall@20: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1000/2641 [4:25:48<35:11:20, 77.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01000, Loss: 0.3610, NDCG@20: 0.0137, Precision@20: 0.0105, Recall@20: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 1050/2641 [4:39:14<34:16:30, 77.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01050, Loss: 0.3567, NDCG@20: 0.0137, Precision@20: 0.0104, Recall@20: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1100/2641 [4:51:46<31:05:09, 72.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01100, Loss: 0.3552, NDCG@20: 0.0137, Precision@20: 0.0104, Recall@20: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 1150/2641 [5:04:49<31:25:22, 75.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01150, Loss: 0.3547, NDCG@20: 0.0138, Precision@20: 0.0106, Recall@20: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1200/2641 [5:17:21<29:04:26, 72.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01200, Loss: 0.3444, NDCG@20: 0.0138, Precision@20: 0.0106, Recall@20: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1250/2641 [5:30:25<29:20:06, 75.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01250, Loss: 0.3426, NDCG@20: 0.0138, Precision@20: 0.0104, Recall@20: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1300/2641 [5:43:28<28:13:28, 75.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01300, Loss: 0.3370, NDCG@20: 0.0138, Precision@20: 0.0105, Recall@20: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1350/2641 [5:56:37<27:31:16, 76.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01350, Loss: 0.3303, NDCG@20: 0.0139, Precision@20: 0.0106, Recall@20: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1400/2641 [6:09:02<24:24:12, 70.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01400, Loss: 0.3201, NDCG@20: 0.0137, Precision@20: 0.0105, Recall@20: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1450/2641 [6:21:50<25:13:40, 76.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01450, Loss: 0.3126, NDCG@20: 0.0137, Precision@20: 0.0105, Recall@20: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1500/2641 [6:34:15<22:27:13, 70.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01500, Loss: 0.3204, NDCG@20: 0.0138, Precision@20: 0.0105, Recall@20: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1550/2641 [6:46:47<21:38:59, 71.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 01550, Loss: 0.3175, NDCG@20: 0.0137, Precision@20: 0.0104, Recall@20: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1599/2641 [6:55:45<3:10:03, 10.94s/it] "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 2):\n",
    "    step = 1\n",
    "    for index in tqdm(train_loader):\n",
    "        loss = train_step(index, num_users, num_items, optimizer)\n",
    "        if step % 50 == 0:\n",
    "            ndcg, precision, recall = test_step(test_mask, 20, num_users)\n",
    "            print(f'Step: {step:05d}, Loss: {loss:.4f}, NDCG@20: {ndcg:.4f}, Precision@20: {precision:.4f}, Recall@20: {recall:.4f}')\n",
    "        step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
